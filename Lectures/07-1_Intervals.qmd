---
title: "Intervals"
subtitle: "Quantifying Uncertainty"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
code-annotations: hover
bibliography: QMLS_Bibliography.bib
csl: evolution.csl
---

## Intervals measure uncertainty in a parameter estimate

```{r}
#| label: setup
#| echo: false

library(tidyverse)
library(cowplot)
library(rethinking)
library(cmdstanr)
library(bayesplot)
library(posterior)

theme_set(theme_cowplot())
source("QMLS_functions.R")

set.seed(644)

```


```{r}

mu1 <- 24.3
mu2 <- 32.5

DD1 <- tibble("Treatment" = rep(c("A", "B"),each = 8),
              "Phenotype" = c(rnorm(8, mu1), rnorm(8, mu2)),
              "DataSet" = "D1")

DD2 <- tibble("Treatment" = rep(c("A", "B"),each = 8),
              "Phenotype" = c(rnorm(8, mu1, 6), rnorm(8, mu2, 6)),
              "DataSet" = "D2")

DD3 <- tibble("Treatment" = rep(c("A", "B"),each = 80),
              "Phenotype" = c(rnorm(80, mu1), rnorm(80, mu2)),
              "DataSet" = "D3")

DD4 <- tibble("Treatment" = rep(c("A", "B"),each = 80),
              "Phenotype" = c(rnorm(80, mu1, 6), rnorm(80, mu2, 6)),
              "DataSet" = "D4")

DD <- rbind(DD1, DD2, DD3, DD4)


DD |>
  ggplot(aes(Treatment, Phenotype)) +
  geom_point(position = position_jitter(width = 0.2, seed = 423479),
             alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", size = 3, color = "red") + 
  facet_wrap(vars(DataSet), nrow = 2)

```


## Intervals measure uncertainty in a parameter estimate {.smaller}

- Standard Confidence Intervals (closed form calculation)  
    - Approximate calculation relying on $\pm 2 \times SEM$ 
    - Exact calculation using a critical *t*-value and appropriate degrees of freedom
- Maximum Likelihood Confidence Intervals
    - Iterate over possible parameter values 
    - Identify the range of parameter values associated with likelihoods around the maximum likelihood estimate
- Bayesian Credible Intervals
    - Region including highest desired percentage of posterior density


## Confidence intervals

> A confidence interval is a range that we expect, with some level of conﬁdence, to include the true value of a population parameter such as the mean. [@Curran-Everett2009-zz]

Our calculation is based on our expectation from sampling the true population distribution repeatedly. Recall this is the basis for the frequentist framework.


## Confidence intervals

The 95% confidence interval for a mean can be estimated by the sample mean ± ~ 2 \times $SE_{\bar{Y}}$.

- This is a reasonable approximation


## Estimating confidence intervals

:::: {.columns}

::: {.column width="50%"}

```{r}
#| fig-height: 10
shade_normal(p = 0.025) +
    theme(text = element_text(size = 24))

```

:::

::: {.column width="50%"}

- $2$ in $\pm 2 \times SEM$ is an approximation
- True value is ~1.96 for a standard normal distribution (assuming infinite sample size)
- Exact confidence intervals rely on the *t*-distribution
    - Increase width of CI for smaller sample size

:::

::::


## Plotting Confidence Intervals

```{r}
DD |>
  ggplot(aes(Treatment, Phenotype)) +
  geom_point(position = position_jitter(width = 0.2, seed = 423479),
             alpha = 0.5) +
  stat_summary(fun = mean, geom = "point", size = 3, color = "red") + 
  stat_summary(fun.data = mean_cl_normal, geom = "errorbar", width = 0.1,
               color = "red", linewidth = 1) +
  facet_wrap(vars(DataSet), nrow=2)

```


## What Exactly Does a Confidence Interval Indicate About a Sample?

> A confidence interval is a range that we expect, with some level of conﬁdence, to include the true value of a population parameter such as the mean. [@Curran-Everett2009-zz]

Our calculation is based on our expectation from sampling the true population distribution repeatedly.

- Recall this is the basis for the frequentist framework.


## Example CI calculation

Mean undulation rate for *n = 8* [gliding snakes](https://www.youtube.com/watch?v=16aGSx9gFO4):

![](http://www.lazerhorse.org/wp-content/uploads/2015/01/Flying-Snake-Chrysopelea.jpg){fig-align="center" width="60%"}

What is the mean undulation rate and ~95% CI for this sample of flying snakes?


## Example CI calculation

```{r}
#| echo: true

undulation_rate <- c(0.9, 1.2, 1.2, 1.3, 1.4, 1.4, 1.6, 2.0)

undulation_mean <- mean(undulation_rate)
undulation_SEM <- sd(undulation_rate) / sqrt(length(undulation_rate))

lower <- undulation_mean - 2 * undulation_SEM
upper <- undulation_mean + 2 * undulation_SEM

c(lower, undulation_mean, upper)

```


## Bayesian Credible Intervals

- Summarize the posterior distributions of Bayesian analyses
- Range of the most plausible parameter estimates given the data and the model
- XX% highest density interval
- XX% quantile


## MCMC sampling

- Most general way to do Bayesian inference
- No complicated integrals
- Requires time and computational power


## MCMC model

```{r}
#| echo: true

model <- "
  data{
    int N;
    array[N] real undulation_rate;
  }
  parameters{
    real<lower=0> mu;
    real<lower=0> sigma;
  }
  model{
    // Priors
    mu ~ normal(1, 0.25);
    sigma ~ normal(0, 1);
    
    // Distribution of undulation_rate
    undulation_rate ~ normal(mu, sigma);
  }
"
```

```{r}
#| label: stan_fit
#| message: false
#| warning: false
#| results: hide

if (FALSE) {
  bayes_model <- cmdstan_model(stan_file = write_stan_file(model))
  fm_bayes <- bayes_model$sample(
    data = list(undulation_rate = undulation_rate,
                N = length(undulation_rate)),
    iter_warmup = 2500,
    iter_sampling = 2500,
    seed = 2236726,
    chains = 4)
  samples <- fm_bayes$draws(variables = c("mu", "sigma"))
  write_rds(x = samples, file = "../data/bayes_model_means.rds")
}

# Read the posterior samples from the saved rds file.
post <- read_rds("../data/bayes_model_means.rds")

```


## MCMC trace plot

```{r}
mcmc_trace(post)
```


## Initial samples

```{r}
post_df <- as_draws_df(post) |> 
  as_tibble()

post_df |> 
  select(mu, sigma, .draw) |> 
  slice(1:20) |> 
  pivot_longer(cols = -.draw, names_to = "Parameter") |> 
  ggplot(aes(.draw, value)) +
  geom_line(alpha = 0.25, linewidth = 1) +
  geom_point(size = 2) +
  facet_grid(Parameter ~ ., scales = "free") +
  labs(y = "Estimate", x = "Sample") +
  scale_x_continuous(breaks = 1:20)
```


## MCMC method

- Current position (has a likelihood)
- Propose a change (has a likelihood)
- Move to proposed values with probability proportional to their ratio
- "Bad" jumps are possible with some non-zero probability


## Current estimates

Sample 1:

```{r}
#| echo: true

post_df[1, ]
rel_liks <- dnorm(undulation_rate,
                  mean = post_df$mu[1],
                  sd = post_df$sigma[1], log = TRUE)
(current_ll <- sum(rel_liks))
```


## Proposed estimates

```{r}
#| echo: true

mu_prop <- 1.37
sigma_prop <- 0.3
rel_liks <- dnorm(undulation_rate,
                  mean = mu_prop,
                  sd = sigma_prop, log = TRUE)
(proposed_ll <- sum(rel_liks))
```

```{r}
#| echo: true
exp(proposed_ll) / exp(current_ll)
```

Ratio > 1, so save these estimates and move to the next sample.

```{r}
current_ll <- proposed_ll
```


## Proposed estimates

```{r}
#| echo: true

proposed_ll <- sum(dnorm(undulation_rate,
                         mean = 1.5, sd = 0.22,
                         log = TRUE))
exp(proposed_ll) / exp(current_ll)
```

Ratio < 1, so the probability of moving is equal the ratio (here ~10%).

- This allows moves to lower likelihood estimates (as long as the probability of moving is not too small).
- `runif(1, min = 0, max = 1)` produces the comparison value


## MCMC sampling

The samples will oscillate around the most probable estimates, *in proportion to their probabilities*.

```{r}
#| fig-align: center

post_long <- post_df |> 
  select(mu, sigma, .draw) |> 
  slice(1:100) |> 
  pivot_longer(cols = -.draw, names_to = "Parameter") |> 
  dplyr::rename(Sample = .draw)

post_means <- post_long |> 
  group_by(Parameter) |> 
  summarize(param_mean = mean(value))

ggplot() +
  geom_line(data = post_long, aes(x = Sample, y = value), alpha = 0.25) +
  geom_point(data = post_long, aes(x = Sample, y = value), size = 2) +
  geom_hline(data = post_means,
             aes(yintercept = param_mean, color = Parameter),
             linewidth = 2, alpha = 0.5) +
  scale_color_manual(values = c("darkblue", "darkred"), name = "Parameter") +
  facet_grid(Parameter ~ ., scales = "free") +
  labs(y = "Estimate") +
  theme(legend.position = "none")
```


## Bayesian credible intervals

Posterior distribution of mean undulation, given, the model (including priors) and data:

```{r}
#| fig-align: center

p <- post_df |> 
  select(mu) |> 
  ggplot(aes(mu)) +
  geom_density(linewidth = 2) +
  labs(y = "Relative Likelihood")
p
```


## Bayesian credible intervals

95% Highest density interval is the most probable location for the mean (given the model and the data).

```{r}
#| fig-width: 12
#| fig-align: center

(cred <- HPDI(post_df$mu, prob = 0.95))
p + 
  geom_vline(xintercept = cred, color = "coral", linewidth = 2)
```


## Interpreting intervals

Frequentist interval: `r round(lower, 2)` -- `r round(upper, 2)`

- Future similar experiments and samples
- Does not indicate the probability of the parameter

Bayesian interval: `r round(cred[1], 2)` -- `r round(cred[2], 2)`

- These data and this model
- Relative probability within a region


## Example uses of intervals

```{r}

set.seed(3575575)

Alive <- rnorm(n = 150, mean = 24.5, sd = 2.6)
Dead <- rnorm(n = 30, mean = 22.0, sd = 2.7)
Group <- c(rep("Alive", 150),
           rep("Dead", 30))

HL <- tibble(Horn_Length = c(Alive, Dead),
             Group = factor(Group))

```
:::: {.columns}

::: {.column width="30%"}

![](https://i.imgur.com/EIfjPa0.jpg){fig-align="center" width=100%}

:::

::: {.column width="70%"}

```{r}
#| echo: true

summary(lm(Horn_Length ~ Group, 
           data = HL))

```

:::

::::


## Bayesian posterior regression lines

```{r}

set.seed(4)
n <- 30
X <- rnorm(n, mean = 10, sd = 1)
Y <- 2.3 * X + rnorm(n, mean = 1, sd = 1)
M <- data.frame(X, Y)

post <- read_rds("../data/bayes_model_OLS.rds")

post_samp <- as_draws_df(post) |>
  as_tibble() |> 
  sample_n(200)

ggplot() +
  geom_abline(data = post_samp, aes(intercept = theta_0, slope = theta_1),
              alpha = 0.2, color = "firebrick") +
  geom_point(data = M, aes(X, Y), size = 3, color = "navy")
```


## References

::: {#refs}
:::
