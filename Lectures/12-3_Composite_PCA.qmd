---
title: "Composite Variables"
author:
  - Elizabeth King
  - Kevin Middleton
format:
  revealjs:
    theme: [default, custom.scss]
    standalone: true
    self-contained: true
    logo: QMLS_Logo.png
    slide-number: true
    show-slide-number: all
code-annotations: hover
bibliography: QMLS_Bibliography.bib
csl: evolution.csl
---



```{r}
#| label: setup
#| echo: false
#| message: false
#| warning: false

library(MASS)
library(tidyverse)
library(cowplot)
library(smatr)
library(factoextra)
library(readxl)
library(plotly)
library(GGally)
library(knitr)

theme_set(theme_cowplot())
```

## Motivation: the curse of dimensionality

Multivariate data is not just a challenge for visualization.

You have too many variables

- Some are redundant in measuring essentially the same thing
- Some are highly correlated with others (multicollinear)
- Some are both

Your number of variables approaches your number of observations.


## What is a composite variable?

> A linear combination of variables

Multiple Regression Makes a Composite Variable

- Linear combination of predictor variables that is maximally correlated with outcome variable
- $y = {\beta_1}X_1 + {\beta_2}X_2 + {\beta_3}X_3$
- $\hat{y}$  is a composite variable


## Multiple regression makes a composite variable

```{r}
Milk <- read_excel("../data/Milk.xlsx", na = "NA") |> 
  dplyr::select(Species, Milk_Energy, Fat, Lactose) |> 
  drop_na()

ggscatmat(Milk)
```


## Milk investment

```{r}
fig <- plot_ly() |>
  add_markers(data = Milk,
              x = ~ Fat,
              y = ~ Lactose,
              z = ~ Milk_Energy,
              size = 1,
              showlegend = FALSE) |>
  hide_colorbar() |>
  layout(scene = list(xaxis = list(title = 'Fat'),
                      yaxis = list(title = 'Lactose'),
                      zaxis = list(title = 'Milk Energy')))

fig
```


## Principal components analysis

*Goals*:

1. Create a set of composite variables that encompasses the shared variation among variables
1. Reduce the dimensionality of a set of variables: from considering all variables separately to considering fewer composite variables, while
1. Accounting for as much of the original variation as possible in the data set 

No predictor or outcome variable. Think of it as a one sided equation.


## Principal components

- Sequential linear combinations of the original variables 
- The resulting composite variables *are uncorrelated with one another*
- The first few usually account for *most* of the variation in the original data


## Principal components

For *q* variables, you get *q* PCs

- First encompasses the maximum variance
- Each in turn maximizes remaining variance while remaining uncorrelated


## Milk investment 

```{r}
ggplot(Milk, aes(Fat, Lactose)) + 
  geom_point() +
  coord_fixed()
```


## Milk investment 

Find the indices of the minimum and maximum of `Fat`

```{r}
#| echo: true

themin <- which.min(Milk$Fat)
themax <- which.max(Milk$Fat)
```

Make a `data.frame` with the points for plotting

```{r}
#| echo: true

minpt <- data.frame(x1 = Milk$Fat[themin], x2 = Milk$Lactose[themin])
maxpt <- data.frame(x1 = Milk$Fat[themax], x2 = Milk$Lactose[themax])
```


## Milk investment 

Orange = Low Fat, High Lactose

Blue = High Fat, Low Lactose

```{r}
ma <- line.cis(Milk$Lactose, Milk$Fat,  method = "MA")

p <- ggplot(Milk, aes(Fat, Lactose)) + geom_point() +
  geom_point(data = minpt, aes(x1, x2), col = "orange", size = 4) +
  geom_point(data = maxpt, aes(x1, x2), col = "blue", size = 4) +
  coord_fixed()
print(p)
```


## Major axis == PC1

Orange = Low Fat, High Lactose

Blue = High Fat, Low Lactose

```{r}
MA_plot <- p +
  geom_abline(slope = ma[2, 1], intercept = ma[1, 1],
              color = "red",
              linewidth = 1.5)
print(MA_plot)
```


## Minor axis == PC2

Orange = Low Fat, High Lactose

Blue = High Fat, Low Lactose

```{r}
raw_plot <- MA_plot +
  geom_abline(slope = -1/ma[2, 1],
              intercept = mean(Milk$Lactose) - -1/ma[2, 1] * mean(Milk$Fat),
              color = "red",
              size = 1.5)
print(raw_plot)
```


## Rotation of the axes about the means

```{r}
#| fig-align: center

z <- prcomp(~ Fat + Lactose, data = Milk,
            center = TRUE, scale. = TRUE)
PC <- data.frame(pc1 = z$x[, 1],
                 pc2 = -1 * z$x[, 2])

minpt <- data.frame(x1 = PC$pc1[themin], x2 = PC$pc2[themin])
maxpt <- data.frame(x1 = PC$pc1[themax], x2 = PC$pc2[themax])

pc_plot <- ggplot(PC, aes(pc1, pc2)) +
  geom_vline(xintercept = 0, color = "red", size = 1.5) +
  geom_hline(yintercept = 0, color = "red", size = 1.5) +
  geom_point() +
  geom_point(data = minpt, aes(x1, x2), col = "orange", size = 4) +
  geom_point(data = maxpt, aes(x1, x2), col = "blue", size = 4) +
  coord_fixed() +
  labs(x = "PC1", y = "PC2")
print(pc_plot)
```


## Comparing PCs

```{r}
plot_grid(raw_plot, pc_plot, ncol = 2)
```


## Principal components

`prcomp()` is the preferred function for PCA (*not* `princomp()`):

```{r}
#| echo: true

z <- prcomp(~ Fat + Lactose, data = Milk,
            center = TRUE, scale. = TRUE)
```

- One sided formula: `~ Fat + Lactose`
- PCA is scale-dependent
    - Centered to a mean of 0
    - Scaled to standard deviation of 1


## `prcomp` objects

```{r}
#| echo: true

str(z)
```

`x` is a matrix of the the principal components


## Proportion of variance (eigenvalues)

```{r}
#| echo: true

summary(z)
```

PC1 explains 97% of the variance in the data.


## Loadings (eigenvectors)

Correlations of scaled variables with composite variables

```{r}
#| echo: true

print(z)
```

- `Lactose` loads negatively on PC1 and PC2
- `Fat` loads positively on PC1 and negatively on PC2
- Magnitudes are more informative with more than 2 variables


## Extracting PC scores

```{r}
#| echo: true

PC <- data.frame(pc1 = z$x[, 1],
                 pc2 = z$x[, 2])
PC
```


## Extracting PC scores

Orange = Low Fat, High Lactose

Blue = High Fat, Low Lactose

```{r}
#| fig-align: center

PC <- data.frame(pc1 = z$x[, 1],
                 pc2 = z$x[, 2])
PC[1,]

pc_plot <- ggplot(PC, aes(pc1, pc2)) +
  geom_vline(xintercept = 0, color = "red", size = 1.5) +
  geom_hline(yintercept = 0, color = "red", size = 1.5) +
  geom_point() +
  geom_point(data = minpt, aes(x1, x2), col = "orange", size = 4) +
  geom_point(data = maxpt, aes(x1, x2), col = "blue", size = 4) +
  geom_point(aes(x= -1.785, y=-0.0636), col="purple", size = 4) +
  geom_segment(x = -1.785, xend = -1.785,
               y = -1, yend = -0.0636, col='purple', lty = 3,
               linewidth = 1.2) +
  geom_segment(x = -3, xend = -1.785,
               y = -0.0636, yend = -0.0636,col='purple', lty = 3,
               linewidth = 1.2) +
  coord_fixed() +
  labs(x = "PC1", y = "PC2")
print(pc_plot)

```


## Milk investment: PCA approach

Do fat and lactose *together* predict milk energy?

```{r}
#| echo: true

Milk <- Milk |> 
  mutate(PC1 = z$x[, 1])

summary(lm(Milk_Energy ~ PC1, data = Milk))
```


## Milk investment: Multiple Regression

Do fat and lactose together independently milk energy after accounting for the other variable?

```{r}
fm_Multi <- lm(Milk_Energy ~ Fat + Lactose, data = Milk)
summary(fm_Multi)
```


## Mammal life history

```{r}
#| echo: true

M <- read_excel("../data/mammals.xlsx", na = "NA") |>
  dplyr::select(litter_size,
                adult_body_mass_g,
                neonate_body_mass_g,
                max_longevity_m,
                sexual_maturity_age_d) |> 
  rename(Litter_Size = litter_size,
         Adult_Mass = adult_body_mass_g,
         Neonate_Mass = neonate_body_mass_g,
         Longevity = max_longevity_m,
         Maturity_Age = sexual_maturity_age_d) |> 
  drop_na()
```


## Mammal life history

`~ .` means all columns

```{r}
#| echo: true

z <- prcomp(~ .,
            data = M,
            center = TRUE,
            scale. = TRUE)
```

Centering and $Z$-scaling are important.

- Should be the default but are not.


## Use `factoextra` for useful functions

```{r}
#| echo: true
#| eval: false

library(factoextra)
```

[factoextra](https://rpkgs.datanovia.com/factoextra/index.html) has several convenience functions for working with PCA.


## Mammal life history

```{r}
#| echo: true

get_eig(z)
```

Eigenvalues are variances. Default R `print()` method returns standard deviations.


## Mammal life history

```{r}
#| echo: true

print(z)
```


## Mammal life history

```{r}
#| echo: true

fviz_eig(z, addlabels = TRUE)
```


## Mammal life history

```{r message=FALSE}
#| echo: true

fviz_pca_var(z)
```


## Mammal life history

```{r message = FALSE}
#| echo: true

fviz_pca_var(z, axes = c(2, 3))
```

## Sample size and other concerns

Suggested sample sizes vary:

- *n* = over 50
- Think about the number of predictor variables

All data:

- Numeric (continuous)
- No missing values


## Best case

- A small number of variables that can be used as surrogates for the larger set without too much loss of information
- Lower dimensional summary of a larger set of variables

PC1:

- Variables that combined account for the most variance
- For morphological data:
    - Can often be a proxy for "size"
    - Remaining PCs are "shape"


## Drawbacks

1. Lose the original variable identity
    - Interpretation can be a challenge
2. If centered and scaled (advised), you lose the original scale of the data

